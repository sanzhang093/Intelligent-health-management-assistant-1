#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æŸ¥çœ‹åŒ»å­¦æ¨ç†æ•°æ®é›†æ ·æœ¬
"""

import json
import os

def view_dataset_samples():
    """æŸ¥çœ‹æ•°æ®é›†æ ·æœ¬"""
    dataset_file = "data/medical_dataset/train.json"
    
    if not os.path.exists(dataset_file):
        print("âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®é›†")
        return
    
    print("ğŸ“Š åŒ»å­¦æ¨ç†æ•°æ®é›†æ ·æœ¬é¢„è§ˆ")
    print("=" * 60)
    
    with open(dataset_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    print(f"å­—æ®µ: {list(data[0].keys())}")
    
    # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
    for i in range(min(3, len(data))):
        sample = data[i]
        print(f"\nğŸ“‹ æ ·æœ¬ {i+1}:")
        print("-" * 40)
        print(f"é—®é¢˜: {sample['Question'][:200]}...")
        print(f"\næ¨ç†é“¾: {sample['Complex_CoT'][:300]}...")
        print(f"\nå›ç­”: {sample['Response'][:200]}...")
        print("-" * 40)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
    question_lengths = [len(sample['Question']) for sample in data[:1000]]
    cot_lengths = [len(sample['Complex_CoT']) for sample in data[:1000]]
    response_lengths = [len(sample['Response']) for sample in data[:1000]]
    
    print(f"é—®é¢˜å¹³å‡é•¿åº¦: {sum(question_lengths)/len(question_lengths):.0f} å­—ç¬¦")
    print(f"æ¨ç†é“¾å¹³å‡é•¿åº¦: {sum(cot_lengths)/len(cot_lengths):.0f} å­—ç¬¦")
    print(f"å›ç­”å¹³å‡é•¿åº¦: {sum(response_lengths)/len(response_lengths):.0f} å­—ç¬¦")

if __name__ == '__main__':
    view_dataset_samples()
